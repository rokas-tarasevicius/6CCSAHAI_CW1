{"script": "Imagine words as tiny magnets\u2014some pull together, others push apart. That\u2019s word meaning! Vector embeddings turn words into numbers, mapping how close or far they are in meaning. For example, \u2018king\u2019 and \u2018queen\u2019 are near, but \u2018king\u2019 and \u2018apple\u2019? Not so much. This helps computers understand language, powering search engines, translations, and even chatbots. Master this, and you\u2019ll unlock how machines \u2018get\u2019 words\u2014just like you do!", "duration": 24.842438, "video_path": "/Users/lianmatsuo/Developer/KCL/6CCSAHAI/coursework_1/backend/video_service_v2/cache/6caa2363a8477fbbcee7541164c090d0.mp4", "topic": "Vector25Aug-V2", "subtopic": "Main Content", "concept": "Vector25Aug-V2", "cache_key": "6caa2363a8477fbbcee7541164c090d0"}